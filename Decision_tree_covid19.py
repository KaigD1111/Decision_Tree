# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mfdsQJAYiOcAe6Lhg1zZc_QC6MU49AzF

imporrt thư viện
"""

from google.colab import drive
drive.mount('/content/drive')
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn import tree
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from numpy import mean
from numpy import absolute
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
import pandas as pd
import numpy as np
from sklearn.metrics import f1_score
from sklearn.metrics import log_loss
from sklearn import decomposition # for PCA 
from sklearn import preprocessing
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
df=pd.read_csv('/content/drive/MyDrive/py/Covid Data.csv')

"""khảo sát data"""

df.describe()

df.nunique()

for i in df.columns:
		(df[i].value_counts())
perc=[]
for col in list(df.columns):
	perc.append(round(len(df[(df[col]==97)| (df[col]==98) | (df[col]==99)])/len(df)*100,2))
	print(((pd.DataFrame([df.columns,perc]).T).rename(columns={0:"Feature",1:"Percentage"})).sort_values(by="Percentage",ascending=False))

"""data visua """

useful_cols=['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', 'DATE_DIED',
		'PNEUMONIA', 'AGE', 'DIABETES', 'COPD', 'ASTHMA', 'INMSUPR',
		'HIPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY',
		'RENAL_CHRONIC', 'TOBACCO', 'CLASIFFICATION_FINAL']
df=df[useful_cols]
df=df.replace({
	'USMER':{97:np.nan,98:np.nan,99:np.nan},
	'MEDICAL_UNIT':{97:np.nan,98:np.nan,99:np.nan},
	'SEX':{97:np.nan,98:np.nan,99:np.nan}, 
	'PATIENT_TYPE':{97:np.nan,98:np.nan,99:np.nan}, 
	'DATE_DIED':{97:np.nan,98:np.nan,99:np.nan},
	'PNEUMONIA':{97:np.nan,98:np.nan,99:np.nan}, 
	'DIABETES':{97:np.nan,98:np.nan,99:np.nan}, 
	'COPD':{97:np.nan,98:np.nan,99:np.nan}, 
	'ASTHMA':{97:np.nan,98:np.nan,99:np.nan}, 
	'INMSUPR':{97:np.nan,98:np.nan,99:np.nan},
	'HIPERTENSION':{97:np.nan,98:np.nan,99:np.nan}, 
	'OTHER_DISEASE':{97:np.nan,98:np.nan,99:np.nan}, 
	'CARDIOVASCULAR':{97:np.nan,98:np.nan,99:np.nan}, 
	'OBESITY':{97:np.nan,98:np.nan,99:np.nan},
	'RENAL_CHRONIC':{97:np.nan,98:np.nan,99:np.nan}, 
	'TOBACCO':{97:np.nan,98:np.nan,99:np.nan}, 
	'CLASIFFICATION_FINAL':{97:np.nan,98:np.nan,99:np.nan}
	})
df=df.dropna(axis=0)
df.loc[df.DATE_DIED=='9999-99-99','DATE_DIED']=2
df.loc[df.DATE_DIED!=2,'DATE_DIED']=1
df.rename(columns={'DATE_DIED':'DIED'},inplace=True)
X = df.drop(["DIED"],axis=1)
import seaborn as sns
for col in df.columns:
		fig = plt.figure(figsize=(15,10))
		if col == 'AGE':
			sns.histplot(data=df, x=df['AGE'],bins=30, kde=True)
		else:
			sns.countplot(x=df[col],hue=df['DIED'])
		#st.pyplot(fig)

"""prepocesssing

"""

from google.colab import drive
drive.mount('/content/drive')
df=pd.read_csv('/content/drive/MyDrive/py/Covid Data.csv')
useful_cols=['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', 'DATE_DIED',
		'PNEUMONIA', 'AGE', 'DIABETES', 'COPD', 'ASTHMA', 'INMSUPR',
		'HIPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY',
		'RENAL_CHRONIC', 'TOBACCO', 'CLASIFFICATION_FINAL']
df=df[useful_cols]
df=df.replace({
	'USMER':{97:np.nan,98:np.nan,99:np.nan},
	'MEDICAL_UNIT':{97:np.nan,98:np.nan,99:np.nan},
	'SEX':{97:np.nan,98:np.nan,99:np.nan}, 
	'PATIENT_TYPE':{97:np.nan,98:np.nan,99:np.nan}, 
	'DATE_DIED':{97:np.nan,98:np.nan,99:np.nan},
	'PNEUMONIA':{97:np.nan,98:np.nan,99:np.nan}, 
	'DIABETES':{97:np.nan,98:np.nan,99:np.nan}, 
	'COPD':{97:np.nan,98:np.nan,99:np.nan}, 
	'ASTHMA':{97:np.nan,98:np.nan,99:np.nan}, 
	'INMSUPR':{97:np.nan,98:np.nan,99:np.nan},
	'HIPERTENSION':{97:np.nan,98:np.nan,99:np.nan}, 
	'OTHER_DISEASE':{97:np.nan,98:np.nan,99:np.nan}, 
	'CARDIOVASCULAR':{97:np.nan,98:np.nan,99:np.nan}, 
	'OBESITY':{97:np.nan,98:np.nan,99:np.nan},
	'RENAL_CHRONIC':{97:np.nan,98:np.nan,99:np.nan}, 
	'TOBACCO':{97:np.nan,98:np.nan,99:np.nan}, 
	'CLASIFFICATION_FINAL':{97:np.nan,98:np.nan,99:np.nan}
	})
df=df.dropna(axis=0)
#df.loc[df.DATE_DIED=='9999-99-99','DATE_DIED']=2
#df.loc[df.DATE_DIED!=2,'DATE_DIED']=1
df.rename(columns={'DATE_DIED':'DIED'},inplace=True)
X = df.drop(["DIED"],axis=1)
#y = df["DIED"]

#input and output 
#X = df.drop('DATE_DIED', axis=1)
#y=df['DEATH']
#dem=len(X.columns)
y= [0 if row=='9999-99-99' else 1 for row in df['DIED']]
#y=X['DEATH']
#X=X.drop('DEATH',axis=1)

from sklearn.preprocessing import StandardScaler, MinMaxScaler
scaler = StandardScaler()
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.tree import DecisionTreeClassifier
my_tree=DecisionTreeClassifier()
my_tree.fit(X_train,y_train)

# độ chính xác mặc định khi chưa tune 
from sklearn.metrics import accuracy_score
y_pred=my_tree.predict(X_test)
print("accuracy :" , accuracy_score(y_test, y_pred))
print("recall:",recall_score(y_test,y_pred))
print("precision :",precision_score(y_test,y_pred))
print("f1_score: ",f1_score(y_test, y_pred, average='weighted'))
print("confusion matrix :" , confusion_matrix(y_test, y_pred))

# !!!!!!tiến hành TUNE !!!!
from sklearn.model_selection import GridSearchCV
tune_treeclass={"criterion" :['gini','entropy'],
                #"splitter":['best', 'random'],
                "max_depth":[1,5,9,11,15],
                "min_samples_split":[2,4,8,16],
                "min_samples_leaf":[1,2,4,8,16],
                #"min_weight_fraction_leaf":[0.1,0.2,0.3],
                #"max_features":[],
                #"random_state":[],
                "max_leaf_nodes":[8,16,32,64],
                "min_impurity_decrease":[0,0.001,0.002],
                #"class_weight":[],
                #"ccp_alpha":[0.1,0.2,0.3],
          }
      
tune_dtc=GridSearchCV(my_tree,param_grid=tune_treeclass,scoring='neg_mean_squared_error',cv=2,verbose=3)
tune_dtc.fit(X_train,y_train)

print(tune_dtc.best_params_)
print(tune_dtc.best_score_)

tune_dtc.cv_results_

df_re = pd.DataFrame(tune_dtc.cv_results_)

df_re

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
my_tree=DecisionTreeClassifier()
my_tree.fit(X_train,y_train)
y_pred=my_tree.predict(X_test)
notun=[]
print("accuracy :" , accuracy_score(y_test, y_pred))
notun.append(accuracy_score(y_test, y_pred))
print("recall:",recall_score(y_test,y_pred))
notun.append(recall_score(y_test,y_pred))
print("precision :",precision_score(y_test,y_pred))
notun.append(precision_score(y_test,y_pred))
print("f1_score: ",f1_score(y_test, y_pred, average='weighted'))
notun.append(f1_score(y_test, y_pred, average='weighted'))
print("confusion matrix :" , confusion_matrix(y_test, y_pred))
my_tree=DecisionTreeClassifier(criterion='gini',max_depth=9  ,max_leaf_nodes=64, min_samples_leaf= 16,
min_samples_split= 2)

my_tree.fit(X_train,y_train)
y_pred=my_tree.predict(X_test)
print("TUN")
tun=[]
print("accuracy tuned  :" , accuracy_score(y_test, y_pred))
tun.append( accuracy_score(y_test, y_pred))
print("recall tuned :",recall_score(y_test,y_pred))
tun.append(recall_score(y_test,y_pred))
print("precision tuned :",precision_score(y_test,y_pred))
tun.append(precision_score(y_test,y_pred))
print("f1_score tuned : ",f1_score(y_test, y_pred, average='weighted'))
tun.append(f1_score(y_test,y_pred,average='weighted'))
print("confusion matrix tuned :")
print(confusion_matrix(y_test, y_pred))
from sklearn.metrics import ConfusionMatrixDisplay
disp = ConfusionMatrixDisplay(confusion_matrix(y_pred, y_test))
disp = disp.plot()

tun

# set width of bar
barWidth = 0.25
fig = plt.subplots(figsize =(12, 8))

# Set position of bar on X axis
br1 = np.arange(len(tun))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
 
# Make the plot
plt.bar(br2, tun, color ='r', width = barWidth,
        edgecolor ='grey', label ='Tuned')
plt.bar(br3, notun, color ='g', width = barWidth,
        edgecolor ='grey', label ='defaunt')
#plt.bar(br3, CSE, color ='b', width = barWidth,
        #edgecolor ='grey', label ='CSE')
 
# Adding Xticks
plt.xlabel('', fontweight ='bold', fontsize = 15)
plt.ylabel('', fontweight ='bold', fontsize = 15)
plt.xticks([r + barWidth for r in range(len(tun))],
        ['accuracy', 'recall', 'precision', 'f1_score', '2019'])
 
plt.legend()
plt.show()

"""prunning with ccp_alphas """

from pathlib import Path  
filepath = Path('/content/drive/MyDrive/py/out.csv')  
filepath.parent.mkdir(parents=True, exist_ok=True)  
df_re.to_csv(filepath)

path = my_tree.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas, impurities = path.ccp_alphas, path.impurities

fig, ax = plt.subplots()
ax.plot(ccp_alphas[:-1], impurities[:-1], marker="o", drawstyle="steps-post")
ax.set_xlabel("effective alpha")
ax.set_ylabel("total impurity of leaves")
ax.set_title("Total Impurity vs effective alpha for training set")

clfs = []
for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(criterion='gini',max_depth=9  ,max_leaf_nodes=64, min_samples_leaf= 1,
min_samples_split= 2,random_state=0,ccp_alpha=ccp_alpha)
    clf.fit(X_train, y_train)
    clfs.append(clf)
print(
    "Number of nodes in the last tree is: {} with ccp_alpha: {}".format(
        clfs[-1].tree_.node_count, ccp_alphas[-1]
    )
)

train_scores = [clf.score(X_train, y_train) for clf in clfs]
test_scores = [clf.score(X_test, y_test) for clf in clfs]

fig, ax = plt.subplots()
ax.set_xlabel("alpha")
ax.set_ylabel("accuracy")
ax.set_title("Accuracy vs alpha for training and testing sets")
ax.plot(ccp_alphas, train_scores, marker="o", label="train", drawstyle="steps-post")
ax.plot(ccp_alphas, test_scores, marker="o", label="test", drawstyle="steps-post")
ax.legend()
plt.show()

my_tree=DecisionTreeClassifier(criterion='gini',max_depth=9  ,max_leaf_nodes=64, min_samples_leaf= 1,
min_samples_split= 2,ccp_alpha=0.00)

my_tree.fit(X_train,y_train)
y_pred=my_tree.predict(X_test)
print("tuned: ",accuracy_score(y_test, y_pred))
print("tuned:",precision_score(y_test,y_pred))
print("tuned:",recall_score(y_test,y_pred))
print("tuned,",confusion_matrix(y_test, y_pred))

import numpy as np
import matplotlib.pyplot as plt
marks=[79,45,22,89,95]
bars=('Roll 1','Roll 2','Roll 3','Roll 4','Roll 5')
y=np.arange(len(bars))
plt.bar(y,marks,color='g')